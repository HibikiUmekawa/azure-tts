import os
from pathlib import Path
import azure.cognitiveservices.speech as speechsdk
from dotenv import load_dotenv

# .env èª­ã¿è¾¼ã¿
load_dotenv()

speech_key = os.getenv("AZURE_SPEECH_KEY")
service_region = os.getenv("AZURE_SPEECH_REGION")

# ===================================================
# ğŸ™ï¸ æ—¥æœ¬èªéŸ³å£°ä¸€è¦§ï¼ˆå®šæ•°é…åˆ—ï¼‰
# ===================================================
JAPANESE_VOICES = [
    {"name": "ja-JP-NanamiNeural", "desc": "æ˜ã‚‹ãå…ƒæ°—ãªå¥³æ€§"},
    {"name": "ja-JP-MayuNeural", "desc": "å¹¼ã‚ã§æŸ”ã‚‰ã‹ã„å£°ï¼ˆãšã‚“ã ã‚‚ã‚“é¢¨ï¼‰"},
    {"name": "ja-JP-KeikoNeural", "desc": "ç©ã‚„ã‹ã§å„ªã—ã„å¥³æ€§"},
    {"name": "ja-JP-AoiNeural", "desc": "è½ã¡ç€ã„ãŸå¥³æ€§ï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹å‘ã‘ï¼‰"},
    {"name": "ja-JP-NaokiNeural", "desc": "è‡ªç„¶ã§èãå–ã‚Šã‚„ã™ã„ç”·æ€§"},
    {"name": "ja-JP-KeitaNeural", "desc": "è‹¥ã‚ã§æ˜ã‚‹ã„ç”·æ€§"},
]

# ===================================================
# ğŸ“– XML ã®å†…å®¹ã‚’èª­ã¿è¾¼ã‚€é–¢æ•°
# ===================================================
def read_text_file(file_path: Path) -> str:
    if not file_path.exists():
        print(f"âŒ æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        return ""
    with open(file_path, "r", encoding="utf-8") as f:
        return f.read().strip()

# ===================================================
# ğŸ”§ éŸ³å£°åˆæˆé–¢æ•°
# ===================================================
def synthesize_speech(text: str, voice_index: int, output_file: Path):
    if not text:
        print(f"âš ï¸ èª­ã¿ä¸Šã’ã‚‹ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã™: {output_file.stem}")
        return

    voice_info = JAPANESE_VOICES[voice_index]
    voice_name = voice_info["name"]

    print(f"\nğŸ¤ [{voice_index}] {voice_name} - {voice_info['desc']}")
    print(f"ğŸ”Š {output_file.stem}.xml ã®å†…å®¹ã‚’éŸ³å£°ã«å¤‰æ›ä¸­...")

    # Azure Speech è¨­å®š
    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=service_region)
    speech_config.speech_synthesis_voice_name = voice_name
    audio_config = speechsdk.audio.AudioOutputConfig(filename=str(output_file))

    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=audio_config)

    result = synthesizer.speak_ssml_async(text).get()

    if result.reason == speechsdk.ResultReason.SynthesizingAudioCompleted:
        print(f"âœ… å‡ºåŠ›å®Œäº†: {output_file.name}")
    elif result.reason == speechsdk.ResultReason.Canceled:
        cancellation = result.cancellation_details
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {cancellation.reason}")
        if cancellation.reason == speechsdk.CancellationReason.Error:
            print(f"è©³ç´°: {cancellation.error_details}")

# ===================================================
# ğŸ§  å®Ÿè¡Œéƒ¨
# ===================================================
if __name__ == "__main__":
    draft_dir = Path(__file__).parent / "draft"
    output_dir = Path(__file__).parent / "output"
    output_dir.mkdir(exist_ok=True)

    # éŸ³å£°é¸æŠï¼ˆNanamiå›ºå®šãªã‚‰ idx=0ï¼‰
    idx = 0

    # -------------------------------
    # ğŸ”¹ ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒXMLãƒ•ã‚¡ã‚¤ãƒ«åã‚’æŒ‡å®š
    # -------------------------------
    filename = input("ğŸ¯ èª­ã¿è¾¼ã‚€ XML ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆä¾‹: text5-2.xmlï¼‰: ").strip()
    xml_path = draft_dir / filename

    if not xml_path.exists():
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {xml_path}")
    else:
        ssml_text = read_text_file(xml_path)
        output_file = output_dir / (xml_path.stem + ".wav")
        synthesize_speech(ssml_text, voice_index=idx, output_file=output_file)
        print("\nğŸ‰ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
